import os
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

from transformers import GPT2Tokenizer, GPT2LMHeadModel
import torch
"""
pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html
"""
import sys
import nbformat

# Load pre-trained model and tokenizer
model_name = 'gpt2-medium'  # You can choose 'gpt2', 'gpt2-medium', 'gpt2-large', or 'gpt2-xl'
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

def generate_suggestions(prompt, chunk_size=512, max_new_tokens=256):
    inputs = tokenizer.encode(prompt, return_tensors='pt')

    suggestions = ""
    for i in range(0, inputs.size(1), chunk_size):
        chunk = inputs[:, i:i + chunk_size]
        attention_mask = torch.ones(chunk.shape, dtype=torch.long)
        outputs = model.generate(chunk, attention_mask=attention_mask, max_new_tokens=max_new_tokens, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
        suggestions += tokenizer.decode(outputs[0], skip_special_tokens=True)

    return suggestions

def generate_debugging_suggestions(error_message, code_context, chunk_size=512, max_new_tokens=256):
    prompt = f"""
    I am a Python debugger. Given the following error message and code context, provide suggestions to fix the code.
    
    Error Message:
    {error_message}
    
    Code Context:
    {code_context}
    """
    return generate_suggestions(prompt, chunk_size, max_new_tokens)

def generate_vulnerability_suggestions(code_context, chunk_size=512, max_new_tokens=256):
    prompt = f"""
    I am a Python security expert. Analyze the following code for potential vulnerabilities and provide suggestions to fix them.
    
    Code Context:
    {code_context}
    """
    return generate_suggestions(prompt, chunk_size, max_new_tokens)

def read_code_from_file(file_path):
    if file_path.endswith('.py'):
        with open(file_path, 'r') as file:
            return file.read()
    elif file_path.endswith('.ipynb'):
        with open(file_path, 'r') as file:
            notebook = nbformat.read(file, as_version=4)
            code_cells = [cell['source'] for cell in notebook.cells if cell.cell_type == 'code']
            return '\n'.join(code_cells)
    else:
        raise ValueError("Unsupported file type. Only .py and .ipynb files are supported.")

def debug_code(file_path):
    code = read_code_from_file(file_path)
    try:
        exec(code, globals())
    except Exception as e:
        error_message = str(e)
        code_context = code
        debugging_suggestions = generate_debugging_suggestions(error_message, code_context)
        
        print("\n=== Debugging Suggestions ===")
        print(debugging_suggestions)

def check_vulnerabilities(file_path):
    code = read_code_from_file(file_path)
    vulnerability_suggestions = generate_vulnerability_suggestions(code)
    
    print("\n=== Vulnerability Suggestions ===")
    print(vulnerability_suggestions)

if __name__ == "__main__":
    if len(sys.argv) != 3 or sys.argv[1] not in ["debug", "check_vulnerabilities"]:
        print("Usage: python llm_debugger.py <debug|check_vulnerabilities> <path_to_python_file_or_ipynb_file>")
    else:
        if sys.argv[1] == "debug":
            debug_code(sys.argv[2])
        elif sys.argv[1] == "check_vulnerabilities":
            check_vulnerabilities(sys.argv[2])
